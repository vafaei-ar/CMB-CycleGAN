{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff6a3d3-eca7-4948-b7dd-ee02f7aaf8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# import tensorflow_addons as tfa\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c32aa3-2830-4184-8a3d-0e7214b8dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exampl:\n",
    "# python cyclegan.py --dataset planck/ --lx $lx --ly $lx --epochs 300 --BS 32 --filters 16 --ndb 2 --nrb 3 --nub 2 --nd 3 --model $lx-l1\n",
    "\n",
    "if not in_notebook():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='MODEL ACTIVITY ANALYZER.')\n",
    "    parser.add_argument('--dataset', default='./dataset', type=str, help='path to dataset')\n",
    "    parser.add_argument('--model', default='model file name', type=str, help='model file name')\n",
    "    parser.add_argument('--lx', default=0, type=int, help='image length')\n",
    "    parser.add_argument('--ly', default=0, type=int, help='image width')\n",
    "    parser.add_argument('--epochs', default=200, type=int, help='number of epochs')\n",
    "    parser.add_argument('--BS', default=32, type=int, help='number of epochs')\n",
    "    parser.add_argument('--filters', default=64, type=int, help='number of epochs')\n",
    "    parser.add_argument('--ndb', default=2, type=int, help='number of epochs') \n",
    "    parser.add_argument('--nrb', default=9, type=int, help='number of epochs') \n",
    "    parser.add_argument('--nub', default=2, type=int, help='number of epochs') \n",
    "    parser.add_argument('--nd', default=3, type=int, help='number of epochs') \n",
    "    \n",
    "#    parser.add_argument('--prefix', default='', type=str, help='path to save the results')\n",
    "#     parser.add_argument('--deep', default=0, type=int, help='Network depth!')\n",
    "#     parser.add_argument('--dpi', default=200, type=int, help='image dpi')\n",
    "    parser.add_argument('--restart', action=\"store_true\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    data_path = args.dataset\n",
    "    lx,ly = args.lx,args.ly\n",
    "    restart = args.restart\n",
    "    epochs = args.epochs\n",
    "    batch_size = args.BS\n",
    "    filters = args.filters\n",
    "    num_downsampling_blocks = args.ndb\n",
    "    num_residual_blocks = args.nrb\n",
    "    num_upsample_blocks = args.nub\n",
    "    num_downsampling = args.nd\n",
    "    \n",
    "    mname = args.model\n",
    "    \n",
    "#     dpi = args.dpi\n",
    "#     DEEP = args.deep\n",
    "else:\n",
    "    data_path = ''\n",
    "    lx,ly = 64,64\n",
    "    restart = 0\n",
    "    epochs = 50\n",
    "    batch_size = 32\n",
    "\n",
    "    filters = 16\n",
    "    num_downsampling_blocks = 2\n",
    "    num_residual_blocks = 3\n",
    "    num_upsample_blocks = 2\n",
    "    num_downsampling = 3\n",
    "\n",
    "    mname = '64-l1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b60282-2764-4de0-9717-11e31dadd56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc784b2-7c7b-4fd9-8418-5f10d8685107",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'models/'\n",
    "ch_mkdir(PREFIX[:-1])\n",
    "\n",
    "def blocker(x,nside):\n",
    "    xx = np.array_split(x, nside, axis=1)\n",
    "    xx = np.concatenate(xx,axis=0)\n",
    "    xx = np.array_split(xx, nside, axis=2)\n",
    "    xx = np.concatenate(xx,axis=0)\n",
    "    return xx\n",
    "\n",
    "\n",
    "csep = 'healpix'\n",
    "train_x0 = np.load(data_path+csep+'.npy')[:10]\n",
    "\n",
    "csep = 'sevem'\n",
    "train_x1 = np.load(data_path+csep+'.npy')[:10]\n",
    "\n",
    "train_x0 = blocker(train_x0,2048//lx)\n",
    "train_x1 = blocker(train_x1,2048//lx)\n",
    "\n",
    "train_x0 = train_x0-train_x0.min()\n",
    "train_x0 = train_x0/train_x0.max()\n",
    "train_x0 = 2*train_x0-1\n",
    "train_x0 = train_x0[:,:,:,None]\n",
    "\n",
    "train_x1 = train_x1-train_x1.min()\n",
    "train_x1 = train_x1/train_x1.max()\n",
    "train_x1 = 2*train_x1-1\n",
    "train_x1 = train_x1[:,:,:,None]\n",
    "\n",
    "test_x0 = train_x0[:20]\n",
    "test_x1 = train_x1[:20]\n",
    "\n",
    "print(train_x0.shape,train_x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07547ac2-08bb-467e-8816-5e64bcd10a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(12,6))\n",
    "irr = np.random.randint(train_x0.shape[0])\n",
    "ax1.imshow(train_x0[irr],cmap='jet')\n",
    "ax2.imshow(train_x1[irr],cmap='jet')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffdb17a-ded0-415a-81bb-d7134c0b3b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_img_size = (256, 256, 1)\n",
    "input_img_size = train_x0.shape[1:]\n",
    "\n",
    "buffer_size = 256\n",
    "\n",
    "# Get the generators\n",
    "gen_G = get_resnet_generator(input_img_size,\n",
    "                             filters=filters,\n",
    "                             num_downsampling_blocks=num_downsampling_blocks,\n",
    "                             num_residual_blocks=num_residual_blocks,\n",
    "                             num_upsample_blocks=num_upsample_blocks,\n",
    "                             name=\"generator_G\")\n",
    "                             \n",
    "gen_F = get_resnet_generator(input_img_size,\n",
    "                             filters=filters,\n",
    "                             num_downsampling_blocks=num_downsampling_blocks,\n",
    "                             num_residual_blocks=num_residual_blocks,\n",
    "                             num_upsample_blocks=num_upsample_blocks,\n",
    "                             name=\"generator_F\")\n",
    "\n",
    "# Get the discriminators\n",
    "disc_X = get_discriminator(input_img_size,\n",
    "                           filters=filters,\n",
    "                           kernel_initializer=kernel_init,\n",
    "                           num_downsampling=num_downsampling,\n",
    "                           name=\"discriminator_X\")\n",
    "disc_Y = get_discriminator(input_img_size,\n",
    "                           filters=filters,\n",
    "                           kernel_initializer=kernel_init,\n",
    "                           num_downsampling=num_downsampling,\n",
    "                           name=\"discriminator_Y\")\n",
    "\n",
    "# Loss function for evaluating adversarial loss\n",
    "adv_loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "# Define the loss function for the generators\n",
    "def generator_loss_fn(fake):\n",
    "    fake_loss = adv_loss_fn(tf.ones_like(fake), fake)\n",
    "    return fake_loss\n",
    "\n",
    "\n",
    "# Define the loss function for the discriminators\n",
    "def discriminator_loss_fn(real, fake):\n",
    "    real_loss = adv_loss_fn(tf.ones_like(real), real)\n",
    "    fake_loss = adv_loss_fn(tf.zeros_like(fake), fake)\n",
    "    return (real_loss + fake_loss) * 0.5\n",
    "\n",
    "# Create cycle gan model\n",
    "cycle_gan_model = CycleGan(\n",
    "    generator_G=gen_G, generator_F=gen_F, discriminator_X=disc_X, discriminator_Y=disc_Y\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "cycle_gan_model.compile(\n",
    "    gen_G_optimizer=keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.5),\n",
    "    gen_F_optimizer=keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.5),\n",
    "    disc_X_optimizer=keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.5),\n",
    "    disc_Y_optimizer=keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.5),\n",
    "    gen_loss_fn=generator_loss_fn,\n",
    "    disc_loss_fn=discriminator_loss_fn,\n",
    ")\n",
    "\n",
    "# if os.path.exists(PREFIX+'{}'.format(mname)):\n",
    "#     cycle_gan_model.loadit(PREFIX+'{}'.format(mname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8728a113-e783-442b-83a2-265422d8ca41",
   "metadata": {},
   "source": [
    "# fake_train_x1 = gen_G(real_train_x0)\n",
    "# fake_train_x0 = gen_F(real_train_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49365c3d-e83f-47ca-a8b1-86c62cf00489",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_model.fit(train_x0, train_x1,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    callbacks=[TqdmCallback(verbose=0)]\n",
    "                    )\n",
    "\n",
    "cycle_gan_model.saveit(PREFIX+'{}'.format(mname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc180ac0-3dfb-4f61-9898-cc13c0ede6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_model.loadit(PREFIX+'{}'.format(mname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272dd3b7-fb05-4009-8bbe-abb70ab3b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4, 3, figsize=(12, 15))\n",
    "#for i, img in enumerate(test_horses.take(4)):\n",
    "for i in range(4):\n",
    "    img = test_x0[i:i+1]\n",
    "    prediction = np.array(cycle_gan_model.gen_G(img, training=False)[0])\n",
    "    ax[i, 0].imshow(img[0],cmap='jet')\n",
    "    ax[i, 1].imshow(prediction,cmap='jet')\n",
    "    ax[i, 2].imshow(np.abs(img[0]-prediction),cmap='jet')\n",
    "    ax[i, 0].set_title(\"Input image\")\n",
    "    ax[i, 1].set_title(\"Translated image\")\n",
    "    ax[i, 2].set_title(\"Difference\")\n",
    "    ax[i, 0].axis(\"off\")\n",
    "    ax[i, 1].axis(\"off\")\n",
    "    ax[i, 2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba9cec-c0ed-421c-a2de-ea13cd5393f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4, 3, figsize=(12, 15))\n",
    "for i in range(4):\n",
    "    img = test_x1[i:i+1]\n",
    "    prediction = np.array(cycle_gan_model.gen_F(img, training=False)[0])\n",
    "    ax[i, 0].imshow(img[0],cmap='jet')\n",
    "    ax[i, 1].imshow(prediction,cmap='jet')\n",
    "    ax[i, 2].imshow(np.abs(img[0]-prediction),cmap='jet')\n",
    "    ax[i, 0].set_title(\"Input image\")\n",
    "    ax[i, 1].set_title(\"Translated image\")\n",
    "    ax[i, 2].set_title(\"Difference\")\n",
    "    ax[i, 0].axis(\"off\")\n",
    "    ax[i, 1].axis(\"off\")\n",
    "    ax[i, 2].axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9748d46-499e-4f47-8010-656950fcc88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d140ab-8190-4e51-a376-f5c928d51345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44294d8-5dd7-4d2a-b12f-47e5c3674842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be04fbe-2400-4140-bf3a-a81da9f262f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu1",
   "language": "python",
   "name": "gpu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
