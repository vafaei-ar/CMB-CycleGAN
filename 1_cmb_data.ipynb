{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to install:\n",
    "# !pip install git+https://github.com/vafaei-ar/ccgpack.git\n",
    "# !pip install healpy\n",
    "# !pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aggressive-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/vafaei-ar/CMB-CycleGAN.git\n",
    "# !cd CMB-CycleGAN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import healpy as hp\n",
    "from ccgpack import sky2patch,download,ch_mkdir,pop_percent\n",
    "from utils import *\n",
    "\n",
    "#from healpy import cartview\n",
    "\n",
    "cmap = plt.cm.jet\n",
    "cmap.set_under('w')\n",
    "cmap.set_bad('gray',1.)\n",
    "\n",
    "if not in_notebook():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='Short sample app')\n",
    "    parser.add_argument('-r', action=\"store_true\", default=False)\n",
    "    parser.add_argument('--nsim', action=\"store\", type=int, default=42)\n",
    "    args = parser.parse_args()\n",
    "    replace = args.r\n",
    "    nsim = args.nsim\n",
    "else:\n",
    "    replace = 0\n",
    "    nsim = 10\n",
    "nside = 2048\n",
    "lmax = 2*nside"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-cameroon",
   "metadata": {},
   "source": [
    "You can download CMB end2end simulations from:\n",
    "https://wiki.cosmos.esa.int/planck-legacy-archive/index.php/CMB_maps#CMB%20simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-wrong",
   "metadata": {},
   "source": [
    "# download template:\n",
    "-     http://pla.esac.esa.int/pla/aio/dx12_v3_{method}_{cmb,noise,noise_hm1,noise_hm2,noise_oe1,noise_oe2}_mc_?????_raw.fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p maps\n",
    "!mkdir -p maps/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(nsim):\n",
    "    !eval {\"wget -q http://pla.esac.esa.int/pla/aio/product-action?SIMULATED_MAP.FILE_ID=dx12_v3_sevem_cmb_mc_{:05d}_raw.fits -O maps/dx12_v3_sevem_cmb_mc_{:05d}_raw.fits\".format(idx,idx)}\n",
    "    !eval {\"wget -q http://pla.esac.esa.int/pla/aio/product-action?SIMULATED_MAP.FILE_ID=dx12_v3_sevem_noise_mc_{:05d}_raw.fits -O maps/dx12_v3_sevem_noise_mc_{:05d}_raw.fits\".format(idx,idx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_temp = 'maps/dx12_v3_{}_{}_mc_{:05d}_raw.fits'\n",
    "csep = 'sevem'\n",
    "typ = 'cmb'\n",
    "\n",
    "for iii in range(nsim):\n",
    "    for csep in ['sevem']:#,'nilc','smica','commander']:\n",
    "        fname1 = path_temp.format(csep,'cmb',iii)\n",
    "        fname2 = path_temp.format(csep,'noise',iii)\n",
    "        m = hp.read_map(fname1,nest=1,verbose=0)+hp.read_map(fname2,nest=1,verbose=0)\n",
    "        patches = sky2patch(m,1)\n",
    "        for j in range(12):\n",
    "            fnsave = 'maps/dataset/{}-{}-{}'.format(csep,iii,j)\n",
    "            np.save(fnsave,patches[j])\n",
    "            plt.imshow(patches[j], cmap=cmap)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(fnsave+'.jpg')\n",
    "            plt.close()\n",
    "\n",
    "cl = np.load('cl_planck_lensed.npy')\n",
    "ll = cl[:lmax,0]\n",
    "cl = cl[:lmax,1]\n",
    "ll = np.concatenate([[0,1],ll])\n",
    "cl = np.concatenate([[0,0],cl])\n",
    "\n",
    "for iii in range(nsim):\n",
    "    m = hp.sphtfunc.synfast(cl, nside=nside, lmax=lmax, mmax=None, alm=0, pol=0, pixwin=0, fwhm=0, sigma=None, new=1, verbose=0)\n",
    "    m = hp.reorder(m , r2n=1)\n",
    "    patches = sky2patch(m,1)\n",
    "    for j in range(12):\n",
    "        fnsave = 'maps/dataset/{}-{}-{}'.format('healpix',iii,j)\n",
    "        np.save(fnsave,patches[j])\n",
    "        plt.imshow(patches[j], cmap=cmap)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fnsave+'.jpg')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csep in ['healpix','sevem']:#,'nilc','smica','commander']:\n",
    "    print(csep)\n",
    "    pps = []\n",
    "    for iii in range(nsim):\n",
    "        for j in range(12):\n",
    "            fnsave = 'maps/dataset/{}-{}-{}.npy'.format(csep,iii,j)\n",
    "            pp = np.load(fnsave)\n",
    "            pps.append(pp)\n",
    "    pps = np.array(pps)\n",
    "    np.save(csep,pps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-bulletin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "silent-advocate",
   "metadata": {},
   "source": [
    "# Second notebook\n",
    "if you are running in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# import tensorflow_addons as tfa\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exampl:\n",
    "# python cyclegan.py --dataset planck/ --lx $lx --ly $lx --epochs 300 --BS 32 --filters 16 --ndb 2 --nrb 3 --nub 2 --nd 3 --model $lx-l1\n",
    "\n",
    "if not in_notebook():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='MODEL ACTIVITY ANALYZER.')\n",
    "    parser.add_argument('--dataset', default='./dataset', type=str, help='path to dataset')\n",
    "    parser.add_argument('--model', default='model file name', type=str, help='model file name')\n",
    "    parser.add_argument('--lx', default=0, type=int, help='image length')\n",
    "    parser.add_argument('--ly', default=0, type=int, help='image width')\n",
    "    parser.add_argument('--epochs', default=200, type=int, help='number of epochs')\n",
    "    parser.add_argument('--BS', default=32, type=int, help='number of epochs')\n",
    "    parser.add_argument('--filters', default=64, type=int, help='number of epochs')\n",
    "    parser.add_argument('--ndb', default=2, type=int, help='number of epochs') \n",
    "    parser.add_argument('--nrb', default=9, type=int, help='number of epochs') \n",
    "    parser.add_argument('--nub', default=2, type=int, help='number of epochs') \n",
    "    parser.add_argument('--nd', default=3, type=int, help='number of epochs') \n",
    "    \n",
    "#    parser.add_argument('--prefix', default='', type=str, help='path to save the results')\n",
    "#     parser.add_argument('--deep', default=0, type=int, help='Network depth!')\n",
    "#     parser.add_argument('--dpi', default=200, type=int, help='image dpi')\n",
    "    parser.add_argument('--restart', action=\"store_true\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    data_path = args.dataset\n",
    "    lx,ly = args.lx,args.ly\n",
    "    restart = args.restart\n",
    "    epochs = args.epochs\n",
    "    batch_size = args.BS\n",
    "    filters = args.filters\n",
    "    num_downsampling_blocks = args.ndb\n",
    "    num_residual_blocks = args.nrb\n",
    "    num_upsample_blocks = args.nub\n",
    "    num_downsampling = args.nd\n",
    "    \n",
    "    mname = args.model\n",
    "    \n",
    "#     dpi = args.dpi\n",
    "#     DEEP = args.deep\n",
    "else:\n",
    "    data_path = ''\n",
    "    lx,ly = 64,64\n",
    "    restart = 0\n",
    "    epochs = 50\n",
    "    batch_size = 32\n",
    "\n",
    "    filters = 16\n",
    "    num_downsampling_blocks = 2\n",
    "    num_residual_blocks = 3\n",
    "    num_upsample_blocks = 2\n",
    "    num_downsampling = 3\n",
    "\n",
    "    mname = '64-l1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'models/'\n",
    "ch_mkdir(PREFIX[:-1])\n",
    "\n",
    "def blocker(x,nside):\n",
    "    xx = np.array_split(x, nside, axis=1)\n",
    "    xx = np.concatenate(xx,axis=0)\n",
    "    xx = np.array_split(xx, nside, axis=2)\n",
    "    xx = np.concatenate(xx,axis=0)\n",
    "    return xx\n",
    "\n",
    "\n",
    "csep = 'healpix'\n",
    "train_x0 = np.load(data_path+csep+'.npy')[:10]\n",
    "\n",
    "csep = 'sevem'\n",
    "train_x1 = np.load(data_path+csep+'.npy')[:10]\n",
    "\n",
    "train_x0 = blocker(train_x0,2048//lx)\n",
    "train_x1 = blocker(train_x1,2048//lx)\n",
    "\n",
    "train_x0 = train_x0-train_x0.min()\n",
    "train_x0 = train_x0/train_x0.max()\n",
    "train_x0 = 2*train_x0-1\n",
    "train_x0 = train_x0[:,:,:,None]\n",
    "\n",
    "train_x1 = train_x1-train_x1.min()\n",
    "train_x1 = train_x1/train_x1.max()\n",
    "train_x1 = 2*train_x1-1\n",
    "train_x1 = train_x1[:,:,:,None]\n",
    "\n",
    "test_x0 = train_x0[:20]\n",
    "test_x1 = train_x1[:20]\n",
    "\n",
    "print(train_x0.shape,train_x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(12,6))\n",
    "irr = np.random.randint(train_x0.shape[0])\n",
    "ax1.imshow(train_x0[irr,:,:,0],cmap='jet')\n",
    "ax2.imshow(train_x1[irr,:,:,0],cmap='jet')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_img_size = (256, 256, 1)\n",
    "input_img_size = train_x0.shape[1:]\n",
    "\n",
    "buffer_size = 256\n",
    "\n",
    "# Get the generators\n",
    "gen_G = get_resnet_generator(input_img_size,\n",
    "                             filters=filters,\n",
    "                             num_downsampling_blocks=num_downsampling_blocks,\n",
    "                             num_residual_blocks=num_residual_blocks,\n",
    "                             num_upsample_blocks=num_upsample_blocks,\n",
    "                             name=\"generator_G\")\n",
    "                             \n",
    "gen_F = get_resnet_generator(input_img_size,\n",
    "                             filters=filters,\n",
    "                             num_downsampling_blocks=num_downsampling_blocks,\n",
    "                             num_residual_blocks=num_residual_blocks,\n",
    "                             num_upsample_blocks=num_upsample_blocks,\n",
    "                             name=\"generator_F\")\n",
    "\n",
    "# Get the discriminators\n",
    "disc_X = get_discriminator(input_img_size,\n",
    "                           filters=filters,\n",
    "                           kernel_initializer=kernel_init,\n",
    "                           num_downsampling=num_downsampling,\n",
    "                           name=\"discriminator_X\")\n",
    "disc_Y = get_discriminator(input_img_size,\n",
    "                           filters=filters,\n",
    "                           kernel_initializer=kernel_init,\n",
    "                           num_downsampling=num_downsampling,\n",
    "                           name=\"discriminator_Y\")\n",
    "\n",
    "# Loss function for evaluating adversarial loss\n",
    "adv_loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "# Define the loss function for the generators\n",
    "def generator_loss_fn(fake):\n",
    "    fake_loss = adv_loss_fn(tf.ones_like(fake), fake)\n",
    "    return fake_loss\n",
    "\n",
    "\n",
    "# Define the loss function for the discriminators\n",
    "def discriminator_loss_fn(real, fake):\n",
    "    real_loss = adv_loss_fn(tf.ones_like(real), real)\n",
    "    fake_loss = adv_loss_fn(tf.zeros_like(fake), fake)\n",
    "    return (real_loss + fake_loss) * 0.5\n",
    "\n",
    "# Create cycle gan model\n",
    "cycle_gan_model = CycleGan(\n",
    "    generator_G=gen_G, generator_F=gen_F, discriminator_X=disc_X, discriminator_Y=disc_Y\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "cycle_gan_model.compile(\n",
    "    gen_G_optimizer=keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.5),\n",
    "    gen_F_optimizer=keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.5),\n",
    "    disc_X_optimizer=keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.5),\n",
    "    disc_Y_optimizer=keras.optimizers.Adam(learning_rate=5e-5, beta_1=0.5),\n",
    "    gen_loss_fn=generator_loss_fn,\n",
    "    disc_loss_fn=discriminator_loss_fn,\n",
    ")\n",
    "\n",
    "# if os.path.exists(PREFIX+'{}'.format(mname)):\n",
    "#     cycle_gan_model.loadit(PREFIX+'{}'.format(mname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-marsh",
   "metadata": {},
   "source": [
    "# fake_train_x1 = gen_G(real_train_x0)\n",
    "# fake_train_x0 = gen_F(real_train_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_model.fit(train_x0, train_x1,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    callbacks=[TqdmCallback(verbose=0)]\n",
    "                    )\n",
    "\n",
    "cycle_gan_model.saveit(PREFIX+'{}'.format(mname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_gan_model.loadit(PREFIX+'{}'.format(mname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4, 3, figsize=(12, 15))\n",
    "#for i, img in enumerate(test_horses.take(4)):\n",
    "for i in range(4):\n",
    "    img = test_x0[i:i+1]\n",
    "    prediction = np.array(cycle_gan_model.gen_G(img, training=False)[0])\n",
    "    ax[i, 0].imshow(img[0],cmap='jet')\n",
    "    ax[i, 1].imshow(prediction,cmap='jet')\n",
    "    ax[i, 2].imshow(np.abs(img[0]-prediction),cmap='jet')\n",
    "    ax[i, 0].set_title(\"Input image\")\n",
    "    ax[i, 1].set_title(\"Translated image\")\n",
    "    ax[i, 2].set_title(\"Difference\")\n",
    "    ax[i, 0].axis(\"off\")\n",
    "    ax[i, 1].axis(\"off\")\n",
    "    ax[i, 2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4, 3, figsize=(12, 15))\n",
    "for i in range(4):\n",
    "    img = test_x1[i:i+1]\n",
    "    prediction = np.array(cycle_gan_model.gen_F(img, training=False)[0])\n",
    "    ax[i, 0].imshow(img[0],cmap='jet')\n",
    "    ax[i, 1].imshow(prediction,cmap='jet')\n",
    "    ax[i, 2].imshow(np.abs(img[0]-prediction),cmap='jet')\n",
    "    ax[i, 0].set_title(\"Input image\")\n",
    "    ax[i, 1].set_title(\"Translated image\")\n",
    "    ax[i, 2].set_title(\"Difference\")\n",
    "    ax[i, 0].axis(\"off\")\n",
    "    ax[i, 1].axis(\"off\")\n",
    "    ax[i, 2].axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "### And some results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-village",
   "metadata": {},
   "source": [
    "![](figs/021.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-houston",
   "metadata": {},
   "source": [
    "![](figs/120.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-dealing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu1",
   "language": "python",
   "name": "gpu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
